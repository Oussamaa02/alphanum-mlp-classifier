# Handwritten Character Recognition

A complete web application that recognizes handwritten digits (0-9) and letters (A-Z) using deep learning. Draw on a canvas and get instant predictions!

**Model Performance:**
- Digits (MNIST): 99.18% accuracy
- Letters (EMNIST): ~90-95% accuracy

## ðŸš€ Deployment

**Ready to deploy?** This project can be deployed to free hosting platforms!

- **Frontend**: Deploy to [Vercel](https://vercel.com) (free)
- **Backend**: Deploy to [Railway](https://railway.app) or [Render](https://render.com) (free tiers available)

ðŸ“– **[See Complete Deployment Guide â†’](./DEPLOYMENT.md)**

## Technologies Used

- **Machine Learning**: TensorFlow, Keras, NumPy
- **Backend**: Flask, Pillow, flask-cors
- **Frontend**: React, TypeScript, react-canvas-draw
- **Data**: MNIST, EMNIST Datasets

## Running Locally

### Running the Application

1. **Backend**
```bash
cd backend
pip install -r requirements.txt
python app.py
```

2. **Frontend**
```bash
cd frontend
npm install
npm start
```

## Model Training

1. Open the Jupyter notebook:
```bash
jupyter notebook model/mnist_emnist_classification.ipynb
```

2. Make sure the kernel is configured to `C:\tfvenv\Scripts\python.exe`

3. Execute all cells 


## Project Structure

```
â”œâ”€â”€ backend/               # Flask API server
â”‚   â”œâ”€â”€ app.py            # Main server file
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ frontend/             # React web application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx      # Main component
â”‚   â”‚   â””â”€â”€ App.css      # Styles
â”‚   â””â”€â”€ package.json     # npm dependencies
â”œâ”€â”€ model/                # ML models and training
â”‚   â”œâ”€â”€ mnist_optimized.h5      # Digit recognition model
â”‚   â”œâ”€â”€ emnist_optimized.h5     # Letter recognition model
â”‚   â”œâ”€â”€ mnist_emnist_classification.ipynb  # Training notebook
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ emnist-letters.mat  # EMNIST dataset
â””â”€â”€ README.md           
```

## Technical Details

### Model Architecture
```
Input (28x28 grayscale image)
    â†“
Conv2D (32 filters, 3x3) + ReLU + BatchNorm + MaxPool
    â†“
Conv2D (64 filters, 3x3) + ReLU + BatchNorm + MaxPool + Dropout(0.5)
    â†“
Flatten
    â†“
Dense(1568) + ReLU + BatchNorm + Dropout(0.5)
Dense(1000) + ReLU + BatchNorm + Dropout(0.5)
Dense(700) + ReLU + BatchNorm + Dropout(0.5)
Dense(300) + ReLU + BatchNorm + Dropout(0.5)
Dense(100) + ReLU + BatchNorm
    â†“
Output (10 or 27 classes) + Softmax
```

### Image Preprocessing Pipeline
```
User draws a 280x280 image
    â†“
Convert to grayscale
    â†“
Resize to 28x28 (training data size)
    â†“
Invert colors (white digits on black background)
    â†“
Normalize pixel values to [0, 1]
    â†“
Reshape to (1, 28, 28, 1)
    â†“
Ready for prediction!
```

## Results

**MNIST Digits:**
- Training: 99.92%
- Validation: 99.60%
- Test: 99.18% (only 82 errors out of 10,000 images!)

**EMNIST Letters:**
- Training: 98.7%
- Validation: 95.1%
- Test: ~94.9%


